---
# https://docs.ansible.com/ansible/latest/user_guide/intro_inventory.html#intro-inventory

all:
  vars:
    # Consider encrypting this file with ansible-vault
    # Docs: https://docs.ansible.com/ansible/latest/user_guide/vault.html
    # Encrypt: `ansible-vault encrypt inventory.yml`

    ### Terraform ###

    # Digital Ocean token for provisioning the bastion server
    # https://www.digitalocean.com/docs/apis-clis/api/create-personal-access-token/
    do_token:

    ### Containers ###

    # Folder and container ownership
    puid: 1000
    pgid: 1000

    # Set the desired timezone for containers
    # `cat /etc/timezone`
    # https://en.wikipedia.org/wiki/List_of_tz_database_time_zones
    # eg. America/Los_Angeles
    tz:

    # Provide your Cloudflare email and global API key for ACME validation
    # through Traefik's DNS challenge
    # https://go-acme.github.io/lego/dns/cloudflare/
    cloudflare_email:
    cloudflare_api_key:
    # Your root domain name with TLD (e.g. example.com)
    root_domain:

    # Provide a directory for storing service configuration locally
    # within container volumes; subdirectories are created by each service
    # eg. /mnt/tank/appdata
    appdata_dir:

    # Provide a directory for storage and local media in container volumes
    # Subdirectories can be created to separate tv, movies, nzbget, etc
    # eg. /mnt/storage
    storage_dir:

    # Bind public facing ports to a specific address
    # for routing traffic through VPN. This is because
    # I route services to through WireGuard via Traefik
    # instead of all host traffic.
    # https://docs.docker.com/compose/compose-file/#ports
    # https://github.com/containous/traefik/issues/5059
    # default: 0.0.0.0
    network_bind_addr:
    homelab_local_ip:

    # Sets the basic authentication to this frontend in CSV format: User:Hash,User:Hash
    # http://www.htaccesstools.com/htpasswd-generator/
    # Please consider using OAuth configured separately
    htpasswd:

    ### Apps ###

    # Google OAuth - https://console.developers.google.com
    # Make sure to add $root_domain under Authorized Domains in the OAuth Concent Screen
    # Set $root_domain in Domain Verification
    oauth_client_id:
    oauth_client_secret:
    # Create random secret `openssl rand -hex 16`
    oauth_secret:
    # set one or multiple emails to allow login
    oauth_whitelist:

    # https://www.plex.tv/claim/ (must be used within 4 minutes)
    plex_claim_code:
    plex_hostname:
    plex_allowed_networks:

    miniflux_password:
    miniflux_postgres_password:

    healthchecks_email:
    healthchecks_password:
    healthchecks_secret_key:

    # For healthchecks,
    smtp_email_from:
    smtp_host: smtp.gmail.com
    smtp_port: 587
    smtp_user:
    smtp_password:

    # Select container to use (roles/compose/tasks)
    containers:
      - plex
      - nzbget
      - sonarr
      - radarr
      - espial
      - miniflux
      - miniflux_db
      - ombi
      - tautulli
      - healthchecks
      - syncthing
      - prometheus
      - oauth
      - traefik

    # absent - A container matching the specified name will be stopped and removed.
    # present - Asserts the existence of a container matching the name and any provided configuration parameters. If no container matches the name, a container will be created. If a container matches the name but the provided configuration does not match, the container will be updated, if it can be. If it cannot be updated, it will be removed and re-created with the requested config. Image version will be taken into account when comparing configuration. Use the recreate option to force the re-creation of the matching container.
    # started - Asserts there is a running container matching the name and any provided configuration. If no container matches the name, a container will be created and started. Use recreate to always re-create a matching container, even if it is running. Use force_restart to force a matching container to be stopped and restarted.
    # stopped - Asserts that the container is first present, and then if the container is running moves it to a stopped state.
    # created - (new feature) just created the image since our podman_systemd role will start the image with systemd
    container_state: created
    # container_recreate: true

    # Containers with a frontend to use with Traefik (roles/traefik/templates)
    frontend_containers:
      - plex
      - nzbget
      - sonarr
      - radarr
      - espial
      - miniflux
      - ombi
      - tautulli
      - healthchecks
      - syncthing
      - oauth
      - traefik

    # Systemd user setup for podman containers - default setup/teardown depends on `container_state` var
    # podman_systemd_action: remove
    # podman_systemd_force_regenerate: true

  children:
    server:
      hosts:
        # Define homelab hostname and vars
        myhost:
          # https://docs.ansible.com/ansible/latest/user_guide/intro_inventory.html#connecting-to-hosts-behavioral-inventory-parameters
          ansible_host: # use `ansible_connection: local` for local
          ansible_user:

          # Config
          ssh_keys_url: https://github.com/<username>.keys # gitlab works, too
          # include or exclude in same order as https://github.com/settings/keys
          # e.g. exclude all but the first line (1!d) or delete specific lines
          ssh_keys_sed_arg: 1d;3d;5d

          # Server host
          upgrade_zfs: false

          # Snapraid
          snapraid_healthchecks_url:

          # Prometheus
          prometheus_install_node_exporter: true
          node_exporter_basic_auth_users:
            randomuser: examplepassword
          prometheus_install_server_config: true
          prometheus_server_config_path: "{{ appdata_dir }}/prometheus/prometheus.yml" # Mounted path
          prometheus_scrape_configs:
            - job_name: prometheus
              static_configs:
                - targets:
                    - localhost:9090
            - job_name: node
              file_sd_configs:
                - files:
                    # Path within the container
                    - /etc/prometheus/file_sd/node.yml
            - job_name: traefik
              metrics_path: /metrics
              static_configs:
                - targets:
                    - "{{ homelab_local_ip }}:9180"
            - job_name: alertmanager
              file_sd_configs:
                - files:
                    - /etc/prometheus/file_sd/alertmanager.yml
            - job_name: grafana
              file_sd_configs:
                - files:
                    - /etc/prometheus/file_sd/grafana.yml
          prometheus_targets:
            node:
              # Add node exporter targets here
              - targets:
                  - "{{ homelab_local_ip }}:9100"
                labels:
                  env: node
            alertmanager:
              - targets:
                  - "{{ homelab_local_ip }}:9093"
                labels:
                  env: home
            grafana:
              - targets:
                  - "{{ homelab_local_ip }}:3002"
                labels:
                  env: home

    bastion:
      hosts:
        # Define bastion hostname and vars
        myremote:
          ansible_python_interpreter: /usr/bin/python3
